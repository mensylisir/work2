## 常用命令 ##

### 运行Jenkins
```
docker run -itd -p 8099:8080 -p 50009:50000 --name jenkins-master --privileged=true  mydemo/jenkins-master:v1.0
java -jar jenkins.war --ajp13Port=-1 --httpPort=8088
```

### 运行Nexus
```
docker run -d --name nexus3 --restart=always -p 8081:8081 -v C:\Workspace\myDemo\nexus:/nexus-data sonatype/nexus3
```

### 查看etcd集群健康状况

```
/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" endpoint health
```

![avatar](query_etcd_cluster_health_status.png)

### 拷贝

```
scp -r -P7122  /lib/systemd/system/etcd.service root@192.168.80.77:/lib/systemd/system/etcd.service
```

### 部署flanneld遇到的坑

```
bash etcd.sh etcd01 192.168.80.76 etcd02=https://192.168.80.77:2380,etcd03=https://192.168.80.78:2380

 /opt/etcd/bin/etcdctl --ca-file= /opt/etcd/bin/ca.pem --cert-file= /opt/etcd/bin/server.pem --key-file= /opt/etcd/bin/server-key.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" cluster-health

bash apiserver.sh 192.168.80.76 https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379


systemctl start kube-apiserver.service  ##开启服务
systemctl enable kube-apiserver.service
systemctl status kube-apiserver.service 
systemctl start kube-controller-manager.service 
systemctl enable kube-controller-manager.service
systemctl status kube-controller-manager.service
systemctl start kube-scheduler.service
systemctl enable kube-scheduler.service
systemctl status kube-scheduler.service


/opt/etcd/bin/etcdctl --ca-file=ca.pem --cert-file=server.pem --key-file=server-key.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" set /coreos.com/network/config '{ "Network": "172.17.0.0/16", "Backend": {"Type": "vxlan"}}'

/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" get /coreos.com/network/config '{ "Network": "172.17.0.0/16", "Backend": {"Type": "vxlan"}}'

bash -x flannel.sh https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379


--etcd-endpoints=https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379
--etcd-cafile=/opt/etcd/ssl/ca.pem 
--etcd-certfile=/opt/etcd/ssl/server.pem 
--etcd-keyfile=/opt/etcd/ssl/server-key.pem 
--etcd-prefix=/coreos.com/network


/opt/etcd/bin/etcdctl --write-out=table --endpoints=http://192.168.80.76:2379,http://192.168.80.77:2379,http://192.168.80.78:2379 endpoint status
/opt/etcd/bin/etcdctl --endpoints=http://192.168.80.76:2379,http://192.168.80.77:2379,http://192.168.80.78:2379 member list
/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" endpoint health --write-out="table"
/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" member list --write-out="table"

/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" endpoint status --write-out="table"

/opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" put /test/word 123456


ETCDCTL_API=2 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" mk /coreos.com/network/config 

ETCDCTL_API=2 /opt/etcd/bin/etcdctl --cacert=/opt/etcd/ssl/ca.pem --key=/opt/etcd/ssl/server-key.pem  --cert=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" set /coreos.com/network/config '{ "Network": "172.17.0.0/16", "Backend": {"Type": "vxlan"}}'


# 这个解决key not found
ETCDCTL_API=2 /opt/etcd/bin/etcdctl --ca-file=/opt/etcd/ssl/ca.pem --key-file=/opt/etcd/ssl/server-key.pem  --cert-file=/opt/etcd/ssl/server.pem --endpoints="https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379" set /coreos.com/network/config '{ "Network": "172.17.0.0/16", "Backend": {"Type": "vxlan"}}'

```

## 复制到其他node

```
yum install -y yum-utils device-mapper-persistent-data lvm2 nano git
```

```
scp -P7122 root@192.168.80.76:/opt/docker/* /usr/bin/

cat > /usr/lib/systemd/system/docker.service <<EOF

[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
ExecStart=/usr/bin/dockerd
ExecReload=/bin/kill -s HUP $MAINPID
LimitNOFILE=infinity
LimitNPROC=infinity
TimeoutStartSec=0
Delegate=yes
KillMode=process
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target
EOF

systemctl start docker.service
systemctl enable docker.service

echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf 
sysctl -p

service network restart
systemctl restart docker
systemctl status docker

mkdir -p /opt/k8s
scp -P7122 root@192.168.80.76:/opt/k8s/flannel-v0.13.0-linux-amd64.tar.gz /opt/k8s
cd /opt/k8s
tar -zxvf flannel-v0.13.0-linux-amd64.tar.gz

mkdir /opt/kubernetes/{cfg,bin,ssl} -p
mv mk-docker-opts.sh flanneld /opt/kubernetes/bin/

scp -P7122 root@192.168.80.88:/opt/k8s/{flannel,kubelet,proxy}.sh /opt/k8s/
scp -P7122 -r root@192.168.80.76:/opt/etcd /opt/
bash -x flannel.sh https://192.168.80.76:2379,https://192.168.80.77:2379,https://192.168.80.78:2379
systemctl status flanneld

nano  /usr/lib/systemd/system/docker.service

[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network-online.target firewalld.service
Wants=network-online.target

[Service]
Type=notify
EnvironmentFile=/run/flannel/subnet.env
ExecStart=/usr/bin/dockerd $DOCKER_NETWORK_OPTIONS
ExecReload=/bin/kill -s HUP
LimitNOFILE=infinity
LimitNPROC=infinity
TimeoutStartSec=0
Delegate=yes
KillMode=process
Restart=on-failure
StartLimitBurst=3
StartLimitInterval=60s

[Install]
WantedBy=multi-user.target

systemctl daemon-reload
systemctl restart docker
systemctl status docker

scp -P7122 -r root@192.168.80.88:/opt/kubernetes /opt/
scp -P7122 root@192.168.80.88:/usr/lib/systemd/system/{kubelet,kube-proxy}.service /usr/lib/systemd/system/
cd /opt/kubernetes/ssl/ 
rm -f /opt/kubernetes/ssl/*
cd /opt/kubernetes/cfg/
nano kubelet
--hostname-override=192.168.80.87 #修改ip
nano kubelet.config
address: 192.168.80.87 #修改ip
nano kube-proxy
--hostname-override=192.168.80.87 # 修改ip

systemctl start kubelet.service
systemctl enable kubelet.service  
systemctl start kube-proxy.service
systemctl enable kube-proxy.service

kubectl get csr # master执行
kubectl certificate approve node-csr-Z1pRzhZ5S3LhxN2cWWZoa-fci3Ro4Se5VWEBTExzLnE # 授权
kubectl get csr # master执行
ubectl get node # master执行
```

### docker pull失败

---

cd /etc/docker/

nano daemon.json

{
  "registry-mirrors": [
    "https://qjzfwfvb.mirror.aliyuncs.com"
  ],
  "insecure-registries": [
    "harbor.rdev.tech",
    "192.168.80.59:80",
    "192.168.80.54:8081"
  ],
  "debug": true,
  "experimental": false
}

systemctl restart docker

---

### 安装 wekan

---

```
docker run -d --restart=always --name wekan-db 192.168.80.54:8081/bitnami/mongo:latest

docker run -d --restart=always --name wekan --link "wekan-db:db" -e "WITH_API=true" -e "MONGO_URL=mongodb://wekan-db:27017/wekan" -e "ROOT_URL=http://192.168.80.89:2000" -p 2000:8080 192.168.80.54:8081/wekan/wekan
```

---

### mondb查看

---

docker exec -it wekan-db bash

mongo

use admin

use wekan

show users

> db.users.find()

---

### 迁移harbor.rdev.tech库

#### 专家库

Dockerfile：

CI/专家库系统配置文件/inner/Dockerfile，需要上传到新库后在gitlab代码里提交修改

---

```
FROM harbor.rdev.tech/gt_zjk/tomcat:1.0
改成
FROM 192.168.80.54:8081/gt_zjk/tomcat:1.0
```

---

---

OA系统

FROM harbor.rdev.tech/ccp-rail-base/tomcat:v8.5.54

http://192.168.71.68:10080/oa/carsoa-server/-/blob/dev/carsoa-eureka/Dockerfile

财务

```
SSP
harbor.rdev.tech/ccp-rail-base/jre:1.8
http://192.168.71.68:10080/finance/ssp  每个子分支
FSSC
FROM harbor.rdev.tech/ccp-rail-base/jre:1.8
http://192.168.71.68:10080/finance/fssc 每个子分支
```

### docker清理

---

**docker system prune -a**

---

---

ssh://git@gitlab.rdev.tech/mkdoc/mkdocs.git

https://gitlab.rdev.tech/mkdoc/mkdocs.git

